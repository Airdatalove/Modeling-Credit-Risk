{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Credit Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "\n",
    "NOTE: dataset has already been reduced in size by removing:\n",
    "* `desc` column: contains long text explanation for each loan\n",
    "* `url` column:  contains a link to each loan on Lending Club which can only be accessed with an investor account\n",
    "* all columns containing more than 50% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Roya/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>171.62</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>119.66</td>\n",
       "      <td>Sep-2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>649.91</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>357.48</td>\n",
       "      <td>Apr-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>67.79</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
       "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
       "2  1077175  1313524.0     2400.0       2400.0           2400.0   36 months   \n",
       "3  1076863  1277178.0    10000.0      10000.0          10000.0   36 months   \n",
       "4  1075358  1311748.0     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade  ... last_pymnt_amnt  \\\n",
       "0   10.65%       162.87     B        B2  ...          171.62   \n",
       "1   15.27%        59.83     C        C4  ...          119.66   \n",
       "2   15.96%        84.33     C        C5  ...          649.91   \n",
       "3   13.49%       339.31     C        C1  ...          357.48   \n",
       "4   12.69%        67.79     B        B5  ...           67.79   \n",
       "\n",
       "  last_credit_pull_d collections_12_mths_ex_med  policy_code application_type  \\\n",
       "0           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "1           Sep-2013                        0.0          1.0       INDIVIDUAL   \n",
       "2           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "3           Apr-2016                        0.0          1.0       INDIVIDUAL   \n",
       "4           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "\n",
       "  acc_now_delinq chargeoff_within_12_mths delinq_amnt pub_rec_bankruptcies  \\\n",
       "0            0.0                      0.0         0.0                  0.0   \n",
       "1            0.0                      0.0         0.0                  0.0   \n",
       "2            0.0                      0.0         0.0                  0.0   \n",
       "3            0.0                      0.0         0.0                  0.0   \n",
       "4            0.0                      0.0         0.0                  0.0   \n",
       "\n",
       "  tax_liens  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007 = pd.read_csv(\"loans_2007.csv\")\n",
    "\n",
    "loans_2007.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42538, 52)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "\n",
    "1. Dropping columns that:\n",
    "    * Leak information from the future (after the loand has already been funded)\n",
    "    * Don't affect a borrower's ability to pay back a loan (e.g. randomly generated ID value by Lending Club)\n",
    "    * formatted poorly and needs to be cleaned up\n",
    "    * requires more data or a lof of porcessing to turn into a useful information\n",
    "    * contain redundant information \n",
    "\n",
    "\n",
    "Going through data 18 columns at a time since there are a total of 52 rows to go through.\n",
    "\n",
    "Following features need to be removed:\n",
    "* `id`: randomly generated field by Lending Club for unique identification purposes only\n",
    "* `member_id`: also a randomly generated field by Lending Club for unique identification purposes only\n",
    "* `funded_amnt`: leaks data from the future (after the loan is already started to be funded)\n",
    "* `funded_amnt_inv`: also leaks data from the future (after the loan is already started to be funded)\n",
    "* `grade`: contains redundant information as the interest rate column (`int_rate`)\n",
    "* `sub_grade`: also contains redundant information as the interest rate column (int_rate)\n",
    "* `emp_title`: requires other data and a lot of processing to potentially be useful\n",
    "* `issue_d`: leaks data from the future (after the loan is already completely funded)\n",
    "\n",
    "NOTE: Lending Club assigns a grade and a sub-grade based on the borrower's interest rate. While the `grade` and `sub_grade` values are categorical, the `int_rate` column contains continuous values, which are better suited for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop(['id','member_id', 'funded_amnt', 'funded_amnt_inv', \n",
    "                              'grade', 'sub_grade', 'emp_title', 'issue_d'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next 18 columns, dropping the following:\n",
    "* `zip_code`: redundant with the addr_state column since only the first 3 digits of the 5 digit zip code are visible (which only can be used to identify the state the borrower lives in)\n",
    "\n",
    "The rest are dropped as they leak data from the future (contains information which isn't available to an investor before the loan is fully funded, therefore don't want to include it in the model):\n",
    "* `out_prncp`\n",
    "* `out_prncp_inv`\n",
    "* `total_pymnt`\n",
    "* `total_pymnt_inv`\n",
    "* `total_rec_prncp`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop(['zip_code', 'out_prncp', 'out_prncp_inv', 'total_pymnt', \n",
    "                              'total_pymnt_inv', 'total_rec_prncp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final 18 columns (features), dropping the following as they all leak data from the future (meaning they describe aspects of the loan after it's already been fully funded and started to be paid off by the borrower:\n",
    "* `total_rec_int`\n",
    "* `total_rec_late_fee`\n",
    "* `recoveries`\n",
    "* `collection_recovery_fee`\n",
    "* `last_pymnt_d`\n",
    "* `last_pymnt_amnt`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop(['total_rec_int', 'total_rec_late_fee', 'recoveries', \n",
    "                              'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42538, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target column - loan status\n",
    "\n",
    "`loan_status` column describes if a loan was:\n",
    "* paid off on time\n",
    "* had delayed payments\n",
    "* was defaulted on the borrower\n",
    "\n",
    "Need to convert column from text values to numerical for training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid                                             33136\n",
       "Charged Off                                             5634\n",
       "Does not meet the credit policy. Status:Fully Paid      1988\n",
       "Current                                                  961\n",
       "Does not meet the credit policy. Status:Charged Off      761\n",
       "Late (31-120 days)                                        24\n",
       "In Grace Period                                           20\n",
       "Late (16-30 days)                                          8\n",
       "Default                                                    3\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on research can tell that:\n",
    "* **Fully Paid**: Loan has been fully paid off. \n",
    "* **Charged Off**: Loan for which there is no longer a reasonable expectation of further payments.\n",
    "* **Does not meet the credit policy. Status:Fully Paid**: While the loan was paid off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    "* **Current**:Loan is up to date on current payments.\n",
    "* **Does not meet the credit policy. Status:Charged Off**: While the loan was charged off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    "* **Late (31-120 days)**: Loan hasn't been paid in 31 to 120 days (late on the current payment).\n",
    "* **In Grace Period**: The loan is past due but still in the grace period of 15 days.\n",
    "* **Late (16-30 days)**: Loan hasn't been paid in 16 to 30 days (late on the current payment).\n",
    "* **Default**: Loan is up to date on current payments.\n",
    "\n",
    "Only the `Fully Paid` and `Charged Off` values describe the final outcome of the loan. The other values describe loans that are still ongoing and where the jury is still out on if the borrower will pay back the loan on time or not. \n",
    "\n",
    "Since I'm interested in being able to predict which of these 2 values a loan will fall under, we can treat the problem as a **binary classification** one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    33136\n",
       "0     5634\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all rows from loans_2007 that contain values other than Fully Paid\n",
    "# or Charged Off for the loan_status column\n",
    "\n",
    "loans_2007 = loans_2007[(loans_2007['loan_status'] =='Fully Paid') | (loans_2007['loan_status'] == 'Charged Off')]\n",
    "\n",
    "mapping_dict = {\n",
    "    \"loan_status\":{\n",
    "        \"Fully Paid\": 1,\n",
    "        \"Charged Off\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "loans_2007 = loans_2007.replace(mapping_dict)\n",
    "\n",
    "loans_2007['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a **class imbalance**. 33,136 loans have been fully paid off, but only 5,634 that were charged off. \n",
    "\n",
    "During training, the model ends up having a strong bias towards predicting the class with more observations in the training set and will rarely predict the class with less observations.\n",
    "\n",
    "The stronger the imbalance, the more biased the model becomes. Will tackle this later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping categorical columns with only one unique value\n",
    "\n",
    "Columns won't be useful as they won't add any information to each loan application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pymnt_plan',\n",
       " 'initial_list_status',\n",
       " 'collections_12_mths_ex_med',\n",
       " 'policy_code',\n",
       " 'application_type',\n",
       " 'acc_now_delinq',\n",
       " 'chargeoff_within_12_mths',\n",
       " 'delinq_amnt',\n",
       " 'tax_liens']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_columns = []\n",
    "\n",
    "columns = loans_2007.columns\n",
    "\n",
    "for col in columns:\n",
    "    #to return set of non-null unique values\n",
    "    non_null = loans_2007[col].dropna()\n",
    "    unique_non_null = non_null.unique()\n",
    "    num_true_unique = len(unique_non_null)\n",
    "    if num_true_unique == 1:\n",
    "        drop_columns.append(col)\n",
    "        \n",
    "loans = loans_2007.drop(drop_columns, axis=1)\n",
    "\n",
    "drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38770, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the features\n",
    "\n",
    "Preparing the data for machine learning by:\n",
    "* handling missing value\n",
    "* converting categorical columns to numeric columns\n",
    "* removing any other extraneous columns encountered through the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_amnt                  0\n",
       "term                       0\n",
       "int_rate                   0\n",
       "installment                0\n",
       "emp_length              1036\n",
       "home_ownership             0\n",
       "annual_inc                 0\n",
       "verification_status        0\n",
       "loan_status                0\n",
       "purpose                    0\n",
       "title                     11\n",
       "addr_state                 0\n",
       "dti                        0\n",
       "delinq_2yrs                0\n",
       "earliest_cr_line           0\n",
       "inq_last_6mths             0\n",
       "open_acc                   0\n",
       "pub_rec                    0\n",
       "revol_bal                  0\n",
       "revol_util                50\n",
       "total_acc                  0\n",
       "last_credit_pull_d         2\n",
       "pub_rec_bankruptcies     697\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = loans.isnull().sum()\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on research know that **employment length** is frequently used in assessing how risky a potential borrower is, so I'll keep this column despite its relatively large amount of missing values.\n",
    "\n",
    "I will inspect the other columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.939438\n",
       "1.0    0.042456\n",
       "NaN    0.017978\n",
       "2.0    0.000129\n",
       "Name: pub_rec_bankruptcies, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pub_rec_bankruptcies\n",
    "\n",
    "loans['pub_rec_bankruptcies'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column offers very little variability, nearly 94% of values are in the same category. Therefore it is unlikely to have much predicting value.\n",
    "\n",
    "Also removing the remaining rows containing null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     11\n",
       "float64    10\n",
       "int64       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans = loans.drop(['pub_rec_bankruptcies'], axis=1)\n",
    "loans = loans.dropna(axis=0)\n",
    "\n",
    "loans.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loan_amnt', 'term', 'int_rate', 'installment', 'emp_length',\n",
       "       'home_ownership', 'annual_inc', 'verification_status', 'loan_status',\n",
       "       'purpose', 'title', 'addr_state', 'dti', 'delinq_2yrs',\n",
       "       'earliest_cr_line', 'inq_last_6mths', 'open_acc', 'pub_rec',\n",
       "       'revol_bal', 'revol_util', 'total_acc', 'last_credit_pull_d'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical columns/features\n",
    "\n",
    "### Rescaling\n",
    "In order to make sure these values are equally weighted within our model, we'll need to rescale the data.\n",
    "\n",
    "Rescaling simply stretches or shrinks the data as needed to be on the same scale, in our case between 0 and 1.\n",
    "\n",
    "\n",
    "In general, however, the regression coefficient is interpreted the same as above, except that the caveat â€˜holding all other independent variables constantâ€™ must be added. The question becomes, can the value of this independent variable be increased by one without changing any of the other variables.\n",
    "\n",
    "After rescaling, the values in each feature has been compressed or stretched so that they are all on the same scale - they have the same minimum and maximum, and the relationship between each point is still the same relative other points in that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>total_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>162.87</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13648.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>59.83</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>84.33</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>339.31</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5598.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>156.46</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>11.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7963.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  installment  annual_inc    dti  delinq_2yrs  inq_last_6mths  \\\n",
       "0     5000.0       162.87     24000.0  27.65          0.0             1.0   \n",
       "1     2500.0        59.83     30000.0   1.00          0.0             5.0   \n",
       "2     2400.0        84.33     12252.0   8.72          0.0             2.0   \n",
       "3    10000.0       339.31     49200.0  20.00          0.0             1.0   \n",
       "5     5000.0       156.46     36000.0  11.20          0.0             3.0   \n",
       "\n",
       "   open_acc  pub_rec  revol_bal  total_acc  \n",
       "0       3.0      0.0    13648.0        9.0  \n",
       "1       3.0      0.0     1687.0        4.0  \n",
       "2       2.0      0.0     2956.0       10.0  \n",
       "3      10.0      0.0     5598.0       37.0  \n",
       "5       9.0      0.0     7963.0       12.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = loans.select_dtypes(include=['int', 'float']).drop(['loan_status'], axis=1)\n",
    "numerical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37675 entries, 0 to 39785\n",
      "Data columns (total 22 columns):\n",
      "term                     37675 non-null object\n",
      "int_rate                 37675 non-null object\n",
      "emp_length               37675 non-null object\n",
      "home_ownership           37675 non-null object\n",
      "verification_status      37675 non-null object\n",
      "loan_status              37675 non-null int64\n",
      "purpose                  37675 non-null object\n",
      "title                    37675 non-null object\n",
      "addr_state               37675 non-null object\n",
      "earliest_cr_line         37675 non-null object\n",
      "revol_util               37675 non-null object\n",
      "last_credit_pull_d       37675 non-null object\n",
      "loan_amnt_scaled         37675 non-null float64\n",
      "installment_scaled       37675 non-null float64\n",
      "annual_inc_scaled        37675 non-null float64\n",
      "dti_scaled               37675 non-null float64\n",
      "delinq_2yrs_scaled       37675 non-null float64\n",
      "inq_last_6mths_scaled    37675 non-null float64\n",
      "open_acc_scaled          37675 non-null float64\n",
      "pub_rec_scaled           37675 non-null float64\n",
      "revol_bal_scaled         37675 non-null float64\n",
      "total_acc_scaled         37675 non-null float64\n",
      "dtypes: float64(10), int64(1), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Rescaling each of the columns so the values range from 0 to 1\n",
    "# Standardisation\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "num_columns = numerical_df.columns\n",
    "\n",
    "for col in num_columns:\n",
    "    loans[col + '_scaled'] = minmax_scale(loans[col])\n",
    "\n",
    "loans = loans.drop(num_columns, axis=1)\n",
    "\n",
    "loans.info()\n",
    "# Normalisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text columns\n",
    "\n",
    "Converting text columns to numerical data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Verified</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Computer</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Jan-1985</td>\n",
       "      <td>83.7%</td>\n",
       "      <td>Jun-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>car</td>\n",
       "      <td>bike</td>\n",
       "      <td>GA</td>\n",
       "      <td>Apr-1999</td>\n",
       "      <td>9.4%</td>\n",
       "      <td>Sep-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>small_business</td>\n",
       "      <td>real estate business</td>\n",
       "      <td>IL</td>\n",
       "      <td>Nov-2001</td>\n",
       "      <td>98.5%</td>\n",
       "      <td>Jun-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>other</td>\n",
       "      <td>personel</td>\n",
       "      <td>CA</td>\n",
       "      <td>Feb-1996</td>\n",
       "      <td>21%</td>\n",
       "      <td>Apr-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.90%</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>wedding</td>\n",
       "      <td>My wedding loan I promise to pay back</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Nov-2004</td>\n",
       "      <td>28.3%</td>\n",
       "      <td>Jan-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term int_rate emp_length home_ownership verification_status  \\\n",
       "0   36 months   10.65%  10+ years           RENT            Verified   \n",
       "1   60 months   15.27%   < 1 year           RENT     Source Verified   \n",
       "2   36 months   15.96%  10+ years           RENT        Not Verified   \n",
       "3   36 months   13.49%  10+ years           RENT     Source Verified   \n",
       "5   36 months    7.90%    3 years           RENT     Source Verified   \n",
       "\n",
       "          purpose                                  title addr_state  \\\n",
       "0     credit_card                               Computer         AZ   \n",
       "1             car                                   bike         GA   \n",
       "2  small_business                   real estate business         IL   \n",
       "3           other                               personel         CA   \n",
       "5         wedding  My wedding loan I promise to pay back         AZ   \n",
       "\n",
       "  earliest_cr_line revol_util last_credit_pull_d  \n",
       "0         Jan-1985      83.7%           Jun-2016  \n",
       "1         Apr-1999       9.4%           Sep-2013  \n",
       "2         Nov-2001      98.5%           Jun-2016  \n",
       "3         Feb-1996        21%           Apr-2016  \n",
       "5         Nov-2004      28.3%           Jan-2016  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_columns_df = loans.select_dtypes(include=['object'])\n",
    "object_columns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial review:\n",
    "\n",
    "* Following columns contain date values that require a significant amount of feature engineering for them to be potentially useful and so will remove these columns:\n",
    "    * **`earlies_cr_line`** : The month the borrower's easlier reported credit line was opened\n",
    "    * **`last_credit_pull_d`**: The most recent month Lending Club pulled credit for this loan \n",
    "* Following columns represent numeric values, that need to be converted:\n",
    "    * **`int_rate`**: interest rate of the loan in %\n",
    "    * **`revol_util`**: revolving line utilisation rate or the amount of credit the borrower is using relative to all available credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = loans.drop(['earliest_cr_line', 'last_credit_pull_d'], axis=1)\n",
    "\n",
    "loans['int_rate'] = loans['int_rate'].str.strip('%').astype('float')\n",
    "loans['revol_util'] = loans['revol_util'].str.strip('%').astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns seem like they represent categorical values, but will confirm by checking the number of unique values in those columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36 months    28234\n",
      " 60 months     9441\n",
      "Name: term, dtype: int64\n",
      "10+ years    8545\n",
      "< 1 year     4513\n",
      "2 years      4303\n",
      "3 years      4022\n",
      "4 years      3353\n",
      "5 years      3202\n",
      "1 year       3176\n",
      "6 years      2177\n",
      "7 years      1714\n",
      "8 years      1442\n",
      "9 years      1228\n",
      "Name: emp_length, dtype: int64\n",
      "RENT        18112\n",
      "MORTGAGE    16686\n",
      "OWN          2778\n",
      "OTHER          96\n",
      "NONE            3\n",
      "Name: home_ownership, dtype: int64\n",
      "Not Verified       16281\n",
      "Verified           11856\n",
      "Source Verified     9538\n",
      "Name: verification_status, dtype: int64\n",
      "CA    6776\n",
      "NY    3614\n",
      "FL    2704\n",
      "TX    2613\n",
      "NJ    1776\n",
      "IL    1447\n",
      "PA    1442\n",
      "VA    1347\n",
      "GA    1323\n",
      "MA    1272\n",
      "OH    1149\n",
      "MD    1008\n",
      "AZ     807\n",
      "WA     788\n",
      "CO     748\n",
      "NC     729\n",
      "CT     711\n",
      "MI     678\n",
      "MO     648\n",
      "MN     581\n",
      "NV     466\n",
      "SC     454\n",
      "WI     427\n",
      "OR     422\n",
      "LA     420\n",
      "AL     420\n",
      "KY     311\n",
      "OK     285\n",
      "KS     249\n",
      "UT     249\n",
      "AR     229\n",
      "DC     209\n",
      "RI     194\n",
      "NM     180\n",
      "WV     164\n",
      "HI     162\n",
      "NH     157\n",
      "DE     110\n",
      "MT      77\n",
      "WY      76\n",
      "AK      76\n",
      "SD      60\n",
      "VT      53\n",
      "MS      19\n",
      "TN      17\n",
      "IN       9\n",
      "ID       6\n",
      "NE       5\n",
      "IA       5\n",
      "ME       3\n",
      "Name: addr_state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = ['term', 'emp_length', 'home_ownership', 'verification_status',\n",
    "        'addr_state']\n",
    "\n",
    "for col in cols:\n",
    "    print(loans[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debt Consolidation                      2068\n",
      "Debt Consolidation Loan                 1599\n",
      "Personal Loan                            624\n",
      "Consolidation                            488\n",
      "debt consolidation                       466\n",
      "                                        ... \n",
      "The Life Changer                           1\n",
      "Building credit, never been in debt.       1\n",
      "PayOffParents                              1\n",
      "Exige                                      1\n",
      "No More High Interest Credit Cards         1\n",
      "Name: title, Length: 18881, dtype: int64\n",
      "debt_consolidation    17751\n",
      "credit_card            4911\n",
      "other                  3711\n",
      "home_improvement       2808\n",
      "major_purchase         2083\n",
      "small_business         1719\n",
      "car                    1459\n",
      "wedding                 916\n",
      "medical                 655\n",
      "moving                  552\n",
      "house                   356\n",
      "vacation                348\n",
      "educational             312\n",
      "renewable_energy         94\n",
      "Name: purpose, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans['title'].value_counts())\n",
    "print(loans['purpose'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on above, columns:\n",
    "* **`home ownership`, `verification_status`, `emp_length`**, **`term`**: \n",
    "    * contain a few discrete categorical values. I will encdoe these columns as **dummy variables** and keep them\n",
    "* **`purpose` and `title`**: \n",
    "    * contain overlapping information. I will keep `purpose` column since it contains a few discrete values. `Title` column has data quality issues since many of the values are repeated with slight modifications.\n",
    "* **`emp_length`**: \n",
    "    * I will treat as a numerical column since the values have ordering (2 years is less than 8 years of employment). I will clean this column using mapping. \n",
    "* **`addr_state`**:\n",
    "    * contains many discrete values and I would need to add 49 dummy variables ot use it for classification. This would make the df much larger and could slow down how quickly the code runs. Therefore, I will remove this column from consideration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning emp_length\n",
    "\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "loans = loans.replace(mapping_dict)\n",
    "loans['emp_length'] = loans['emp_length'].astype('float')\n",
    "\n",
    "# dropping title and addr_state\n",
    "loans = loans.drop(['title', 'addr_state'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy variables for remaining categorical columns\n",
    "dummy_df = pd.get_dummies(loans[['home_ownership', 'verification_status','purpose', 'term']]).astype('int')\n",
    "\n",
    "loans = pd.concat([loans, dummy_df], axis=1)\n",
    "\n",
    "loans = loans.drop(['home_ownership', 'verification_status','purpose', 'term'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37675 entries, 0 to 39785\n",
      "Data columns (total 38 columns):\n",
      "int_rate                               37675 non-null float64\n",
      "emp_length                             37675 non-null float64\n",
      "loan_status                            37675 non-null int64\n",
      "revol_util                             37675 non-null float64\n",
      "loan_amnt_scaled                       37675 non-null float64\n",
      "installment_scaled                     37675 non-null float64\n",
      "annual_inc_scaled                      37675 non-null float64\n",
      "dti_scaled                             37675 non-null float64\n",
      "delinq_2yrs_scaled                     37675 non-null float64\n",
      "inq_last_6mths_scaled                  37675 non-null float64\n",
      "open_acc_scaled                        37675 non-null float64\n",
      "pub_rec_scaled                         37675 non-null float64\n",
      "revol_bal_scaled                       37675 non-null float64\n",
      "total_acc_scaled                       37675 non-null float64\n",
      "home_ownership_MORTGAGE                37675 non-null int64\n",
      "home_ownership_NONE                    37675 non-null int64\n",
      "home_ownership_OTHER                   37675 non-null int64\n",
      "home_ownership_OWN                     37675 non-null int64\n",
      "home_ownership_RENT                    37675 non-null int64\n",
      "verification_status_Not Verified       37675 non-null int64\n",
      "verification_status_Source Verified    37675 non-null int64\n",
      "verification_status_Verified           37675 non-null int64\n",
      "purpose_car                            37675 non-null int64\n",
      "purpose_credit_card                    37675 non-null int64\n",
      "purpose_debt_consolidation             37675 non-null int64\n",
      "purpose_educational                    37675 non-null int64\n",
      "purpose_home_improvement               37675 non-null int64\n",
      "purpose_house                          37675 non-null int64\n",
      "purpose_major_purchase                 37675 non-null int64\n",
      "purpose_medical                        37675 non-null int64\n",
      "purpose_moving                         37675 non-null int64\n",
      "purpose_other                          37675 non-null int64\n",
      "purpose_renewable_energy               37675 non-null int64\n",
      "purpose_small_business                 37675 non-null int64\n",
      "purpose_vacation                       37675 non-null int64\n",
      "purpose_wedding                        37675 non-null int64\n",
      "term_ 36 months                        37675 non-null int64\n",
      "term_ 60 months                        37675 non-null int64\n",
      "dtypes: float64(13), int64(25)\n",
      "memory usage: 11.2 MB\n"
     ]
    }
   ],
   "source": [
    "loans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions \n",
    "\n",
    "The algorithm will make predictions about whether or not a loan will be paid off on time, which is contained in the `loan_status` column of the clean dataset.\n",
    "\n",
    "NOTE: there's a class imbalance in our target column, `loan_status`. There are about 6 times as many loans that were paid off on time (positive case, label of 1) than those that weren't (negative case, label of 0). \n",
    "\n",
    "Imbalances can cause issues with many machine learning algorithms, where they appear to have high accuracy, but actually aren't learning from the training data. Because of its potential to cause issues, we need to keep the class imbalance in mind as we build machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error metric (set up)\n",
    "\n",
    "Before diving in and selecting an algorithm to apply to the data, I need to select an error metric, that will help me figure out when the model is performing well, and when it's performing poorly. \n",
    "\n",
    "It will help determine if the algorithm will make me money or lose me money. Want to fund enough loans that are paid off on time to offset our losses from loans that aren't paid off.\n",
    "\n",
    "Primarily concerned with 2 types of misclassification:\n",
    "* **false positives**: we predict that a loan will be paid off on time, but it actually isn't.This costs us money, since we fund loans that lose us money. \n",
    "* **false negatives**: we predict that a loan won't be paid off on time, but it actually would be paid off on time. This loses us potential money, since we didn't fund a loan that actually would have been paid off.\n",
    "\n",
    "Viewing this problem from the standpoint of a conservative investor, we need to treat false positives differently than false negatives. \n",
    "\n",
    "A conservative investor would want to minimize risk, and avoid false positives as much as possible. They'd be more okay with missing out on opportunities (false negatives) than they would be with funding a risky loan (false positives).\n",
    "\n",
    "### Class imbalance\n",
    "\n",
    "We mentioned earlier that there is a significant class imbalance in the loan_status column. There are 6 times as many loans that were paid off on time (1), than loans that weren't paid off on time (0). This causes a major issue when we use accuracy as a metric. This is because due to the class imbalance, a classifier can predict 1 for every row, and still have high accuracy. \n",
    "\n",
    "This is why it's important to always be aware of imbalanced classes in machine learning models, and to adjust your error metric accordingly. In this case, **we don't want to use accuracy, and should instead use metrics that tell us the number of false positives and false negatives**.\n",
    "\n",
    "This means that we should optimize for:\n",
    "\n",
    "* **high recall (true positive rate)**\n",
    "* **low fall-out (false positive rate)**\n",
    "\n",
    "\n",
    "This divides all the cases where we thought a loan would be paid off but it wasn't by all the loans that weren't paid off. i.e.  **\"the percentage of the loans that shouldn't be funded that I would fund\"**:\n",
    "\n",
    "`fpr = fp / (fp + tn)`\n",
    "\n",
    "This divides all the cases where we thought a loan would be paid off and it was by all the loans that were paid off. i.e **\"the percentage of loans that should be funded that I would fund\"**:\n",
    "\n",
    "`tpr = tp / (tp + fn)`\n",
    "\n",
    "Generally, if we want to reduce false positive rate, true positive rate will also go down. This is because if we want to reduce the risk of false positives, we wouldn't think about funding riskier loans in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with K-fold Cross Validation\n",
    "\n",
    "K-fold cross validation gives a more realistic depiction of the accuracy of the model and prevents overfitting. \n",
    "\n",
    "Overfitting can happen when we generate prediction using the same data that we trained our model on. When we use this to evaluate error, we get an unrealistically high depiction of how accurate the algorithm is, because it already \"knows\" the correct answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate: 0.9940679077084426\n",
      "False Positive Rate 0.9928923988153998\n"
     ]
    }
   ],
   "source": [
    "target = loans['loan_status']\n",
    "features = loans.drop(['loan_status'], axis=1)\n",
    "\n",
    "# Instantiate model object.\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=2000)\n",
    "\n",
    "# Make predictions using 3-fold cross-validation.\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "\n",
    "# Converting predictions to pandas series object\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "\n",
    "# Rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "print(\"True Positive Rate:\", tpr)\n",
    "print(\"False Positive Rate\", fpr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalising the classifier\n",
    "\n",
    "Even though we're not using accuracy as an error metric, the classifier is, and it isn't accounting for the imbalance in the classes. There are a few ways to get a classifier to correct for imbalanced classes. The two main ways are:\n",
    "\n",
    "* Use oversampling and undersampling to ensure that the classifier gets input that has a balanced number of each class.\n",
    "* Tell the classifier to penalize misclassifications of the less prevalent class more than the other class.\n",
    "\n",
    "With first method have to:\n",
    "1. Throw out many rows of data\n",
    "2. Copy rows multiple times\n",
    "3. Generate fake data\n",
    "\n",
    "None of these techniques are especially easy. \n",
    "Second method is easier to implement using scikit-learn:\n",
    "* set `class_weight` to parameter `balanced` when creating LogisticRegression instance. Tells scikit-learn to penalize the misclassification of the minority class during the training process. The penalty means that the logistic regression classifier pays more attention to correctly classifying rows where `loan_status` is `0`. This lowers accuracy when loan_status is `1`, but raises accuracy when `loan_status` is `0`.\n",
    "\n",
    "By setting the `class_weight` parameter to `balanced`, the penalty is set to be inversely proportional to the class frequencies. You can read more about the parameter here. This would mean that for the classifier, correctly classifying a row where `loan_status` is `0` is `6` times more important than correctly classifying a row where `loan_status` is `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate: 0.6312270582066072\n",
      "False Positive Rate 0.6159921026653504\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model object.\n",
    "lr = LogisticRegression(class_weight = 'balanced', solver='lbfgs', max_iter=2000)\n",
    "\n",
    "# Make predictions using 3-fold cross-validation.\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "\n",
    "# Converting predictions to pandas series object\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "print(\"True Positive Rate:\", tpr)\n",
    "print(\"False Positive Rate\", fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Penalties\n",
    "\n",
    "We can try to lower the false positive rate further by assigning a harsher penalty for misclassifying the negative class. While setting `class_weight` to balanced will automatically set a penalty based on the number of `1s` and `0s` in the column, we can also set a manual penalty. In the last screen, the penalty scikit-learn imposed for misclassifying a `0` would have been around `5.89` (since there are `5.89` times as many `1s` as `0s`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate: 0.3783757210277923\n",
      "False Positive Rate 0.36386969397828234\n"
     ]
    }
   ],
   "source": [
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(class_weight=penalty, solver='lbfgs', max_iter=2000)\n",
    "\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "print(\"True Positive Rate:\", tpr)\n",
    "print(\"False Positive Rate\", fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(df, k):\n",
    "    target = loans(['loan_status'])\n",
    "    features = loans.drop(['loan_status'], axis=1)\n",
    "    \n",
    "    # Instantiating model & implementing k-fold cross validation using k-folds\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    lr = LogisticRegression()\n",
    "    predictions = cross_val_predict(lr, features, target, cv=kf)\n",
    "    \n",
    "    # determining true positive rate and false positive rate\n",
    "    # converting predictions to pandas series object\n",
    "    predictions = pd.Series(predictions)\n",
    "    \n",
    "    # False positives\n",
    "    fp_filter = (predictions == 1) & (loans['loans_status'] == 0)\n",
    "    fp = len(predictions[fp_filter])\n",
    "    \n",
    "    # True positives\n",
    "    tp_filter = (predictions == 1) & (loans['loans_status'] == 1)\n",
    "    tp = len(predictions[tp_filter])\n",
    "    \n",
    "    # False negatives\n",
    "    fn_filter = (predictions == 0) & (loans['loans_status'] == 1)\n",
    "    fn = len(predictions[fn_filter])\n",
    "    \n",
    "    # True negatives\n",
    "    tn_filter = (predictions == 0) & (loans['loans_status'] == 0)\n",
    "    tn = len(predictions[tn_filter])\n",
    "    \n",
    "    # Rates\n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
